{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8c3625-88e8-4bfc-aff2-6fca47198147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "from torch import nn\n",
    "from easy_tpp.preprocess.event_tokenizer import EventTokenizer\n",
    "from easy_tpp.config_factory import DataSpecConfig\n",
    "from models.encoders.gru import GRUTPPEncoder\n",
    "from models.decoders.rmtpp import RMTPPDecoder, RMTPPLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2409feff-7f5d-4b14-be2d-8c8cbad5fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPPModel(nn.Module):\n",
    "    def __init__(self, config, hidden_dim, mlp_dim, device):\n",
    "        super(TPPModel, self).__init__()\n",
    "        self.encoder = GRUTPPEncoder(config, hidden_dim=hidden_dim)\n",
    "        self.decoder = RMTPPDecoder(hidden_dim=hidden_dim, num_event_types=config.num_event_types, mlp_dim=mlp_dim, device=device)\n",
    "        self.criterion = RMTPPLoss(device=device, ignore_index=config.pad_token_id)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        hidden_states = self.encoder(batch)\n",
    "        decoder_output = self.decoder(hidden_states)\n",
    "        return decoder_output\n",
    "\n",
    "    def compute_loss(self, batch, decoder_output):\n",
    "        time_loss, mark_loss, total_loss = self.criterion(\n",
    "            decoder_output,\n",
    "            batch[\"time_delta_seqs\"],\n",
    "            batch[\"type_seqs\"],\n",
    "            batch[\"sequence_length\"]\n",
    "        )\n",
    "        return time_loss, mark_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37bc683-e66c-436c-b9ff-d7f8674086e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dict = pkl.load(open('data/earthquake/dev.pkl', 'rb'))\n",
    "test_dict = pkl.load(open('data/earthquake/test.pkl', 'rb'))\n",
    "train_dict = pkl.load(open('data/earthquake/train.pkl', 'rb'))\n",
    "\n",
    "def prepare_data(raw_data, config):\n",
    "    tokenizer = EventTokenizer(config)\n",
    "    tokenizer.padding_side = 'right'\n",
    "\n",
    "    input_data = {\n",
    "        'time_seqs': [[x[\"time_since_start\"] for x in seq] for seq in raw_data],\n",
    "        'type_seqs': [[x[\"type_event\"] for x in seq] for seq in raw_data],\n",
    "        'time_delta_seqs': [[x[\"time_since_last_event\"] for x in seq] for seq in raw_data]\n",
    "    }\n",
    "    \n",
    "    filtered_data = {\n",
    "        k: [seq for seq in v if len(seq) > 0]\n",
    "        for k, v in input_data.items()\n",
    "    }\n",
    "    \n",
    "    sequence_length = torch.tensor([len(seq) for seq in filtered_data['type_seqs']])\n",
    "    \n",
    "    batch = tokenizer.pad(filtered_data, return_tensors='pt', return_attention_mask=False)\n",
    "    batch['sequence_length'] = sequence_length\n",
    "    \n",
    "    return batch\n",
    "\n",
    "\n",
    "dim_process = train_dict['dim_process']\n",
    "config = DataSpecConfig.parse_from_yaml_config({\n",
    "    'num_event_types': dim_process,\n",
    "    'pad_token_id': dim_process\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b124b478-9ac7-43e9-82d4-379b03051766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Loss: 0.9263450503349304\n",
      "Mark Loss: 2.2181396484375\n",
      "Total Loss: 3.144484758377075\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 128\n",
    "MLP_DIM = 64\n",
    "device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
    "train_data = train_dict['train']\n",
    "processed_data = prepare_data(train_data, config)\n",
    "model = TPPModel(config, hidden_dim=HIDDEN_DIM, mlp_dim=MLP_DIM, device=device).to(device)\n",
    "decoder_output = model(processed_data)\n",
    "time_loss, mark_loss, total_loss = model.compute_loss(processed_data, decoder_output)\n",
    "\n",
    "print(\"Time Loss:\", time_loss.item())\n",
    "print(\"Mark Loss:\", mark_loss.item())\n",
    "print(\"Total Loss:\", total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da29c293-6708-4c8d-86ee-af1c7c2dd81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Time Loss: 0.9271682500839233\n",
      "Test Mark Loss: 2.234062671661377\n",
      "Test Total Loss: 3.16123104095459\n"
     ]
    }
   ],
   "source": [
    "test_data = test_dict['test']\n",
    "processed_test_data = prepare_data(test_data, config)\n",
    "model.eval()\n",
    "processed_test_data = {k: v.to(device) for k, v in processed_test_data.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_decoder_output = model(processed_test_data)\n",
    "    test_time_loss, test_mark_loss, test_total_loss = model.compute_loss(processed_test_data, test_decoder_output)\n",
    "\n",
    "print(\"Test Time Loss:\", test_time_loss.item())\n",
    "print(\"Test Mark Loss:\", test_mark_loss.item())\n",
    "print(\"Test Total Loss:\", test_total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c609a-2584-4a22-bddb-0208ef9876f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
